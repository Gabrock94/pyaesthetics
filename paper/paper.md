---
title: 'pyaesthetics: A Python package for the estimation of visual features from still images'
tags:
  - Python
  - Aesthetics
  - Features extraction
  - Image analysis

authors:
  - name: Giulio Gabrieli
    orcid: 0000-0002-9846-5767
    equal-contrib: false
    affiliation: "1"

affiliations:
 - name: Center for Life Nano- and Neuro-Science, Istituto Italiano di Tecnologia, 00161, Rome, Italy
   index: 1

date: 6 September 2024
bibliography: paper.bib
---

# Summary

Empirical aesthetics is an interdisciplinary research field that aims to understand how people experience, evaluate, and create objects aesthetically, combining insights from psychology, neuroscience, and aesthetics. The focus of empirical aesthetics are mainly  visual and auditory stimuli, with a particular focus on beauty and artistic expression.
Despite the volume of research on visual empirical aesthetics, the majority of the studies studies often analyze only a limited subset of visual properties. The focus on a narrow set of features can be partly attributed to the lack of tools that efficiently estimate a wide range of visual features from images. The current methods for estimate visual features are affected by the variations in implementation, leading to significant challenges in result reproducibility. The `pyaesthetics` package is designed to streamline and simplify the feature estimation process by providing access to a variety of functions for estimation of a range of visual properties.

# Statement of Need

`pyaesthetics` is a Python package for estimating visual features from still images. The package addresses the lack of available free, open-source, and easy-to-use tools for estimating a wide range of visual features. The API for `pyaesthetics` was designed to provide modules for various visual features commonly used in empirical aesthetics studies. It also offers simple entry points for conducting automated analysis for users with limited coding knowledge.

Among the features, `pyaesthetics` allows for the estimation of brightness, contrast, saturation, visual complexity, symmetry, colorfulness, and color distribution. The updated list of features that can be estimated with `pyaesthetics` is available in the [repository of the project](https://github.com/Gabrock94/pyaesthetics) as well as in the [documentation of the project](https://prettywebsite.readthedocs.io/en/latest/index.html), together with installation instructions, a getting started guide, and a few examples of applications. `pyaesthetics` can be used to extract single or multiple features from images, and for features where visualization helps in the interpretation of the results (e.g., visual complexity by quadratic tree decomposition), plotting utilities are provided (e.g.: Quadratic Tree Decomposition, Figure 1).

![Sample of a figure generated by `pyaesthetics`'s plotting utilities. The image depicts the analysis of visual complexity, estimated via quadratic tree decomposition, of a still image from the AVI14 dataset [@miniukovich2014quantification]. Each square represents a leaf of the decomposition tree, with the total number of leaves providing a measure of visual complexity; a higher number of leaves indicates greater visual complexity. The visual representation helps in understanding which parts of the image contribute most to the overall visual complexity.](QTDsample.png){ width=100% }

`pyaesthetics` is primarily aimed at researchers in the field of empirical aesthetics. However, its modules can also be useful for researchers in the Social Sciences, particularly Psychology, and Neuroscience, to explore the visual properties of stimuli used in various research projects (e.g. matching the brightness of visual images). Additionally, `pyaesthetics` may be employed by visual designers, artists, and other individuals who need to analyze the visual properties of images of different nature(e.g. color palette extraction, Figure 2). 

![Sample of three different color palettes of 5 different colors generated from a source figure (A). B represents a palette obtained using 16 named colors, C a palette using 140 named colors, while D represents a palette obtained with no named colors (colors clustering).](palettes.png){ width=100% }

`pyaesthetics` is distributed under the GNU General Public License (Version 3), and the source code is available in a [public Git repository](https://github.com/Gabrock94/pyaesthetics), while the [documentation of the project](https://prettywebsite.readthedocs.io/en/latest/index.html) is served via Read the Docs.

# Ease of Use

To simplify the adoption of `pyaesthetics`, the package provides a module that automates the estimation of all available features. This module allows users who are not familiar with Python or any other coding language to easily integrate `pyaesthetics` into their workflow. The module provides functions to conduct a complete analysis with default parameters that are suitable for a variety of applications.

An example of using the automated analysis module is shown below.

```python
import pyaesthetics

# Define the path to a sample image
path_to_img = "/path/to/image/image.jpg"

# Perform a subset of the analysis using standard parameters
results = pyaesthetics.analysis.analyze_image(path_to_img, method="complete")
```

# Use in Scientific Publications

The package has already been utilized in several peer-reviewed scientific publications and theses. The package was used by @bizzego2022dataset and @liu2024mothers to verify that the visual complexity of different visual stimuli was consistent across trials, by @gabrieli2023machine to investigate the effect of various visual features of still images of websites on participants' aesthetic judgments of the websites, by @cianfanelli2023binding to investigate the visual complexity of IAPS images, by @music2023beautification to explore which visual features contribute to the perception of beauty in images, and by @Veldhuizen2024 to investigate which aesthetic features are most important in influencing consumersâ€™ aesthetic judgments of packaging labels.

# Acknowledgements

We acknowledge support from Gianluca Esposito and Giulia Scapin during the genesis of this project, and Marith Veldhuizen for her input on the introduction of novel features.

This project was also supported by GitKraken's Open Source Project Sponsorship.

# References