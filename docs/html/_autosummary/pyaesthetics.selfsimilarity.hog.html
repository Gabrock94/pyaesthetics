<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>pyaesthetics.selfsimilarity.hog &#8212; pyaesthetics 0.0.8.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css?v=c058f7c8" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css?v=27fed22d" />
    <script src="../_static/documentation_options.js?v=a6cd5f1d"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="pyaesthetics-selfsimilarity-hog">
<h1>pyaesthetics.selfsimilarity.hog<a class="headerlink" href="#pyaesthetics-selfsimilarity-hog" title="Link to this heading">¶</a></h1>
<dl class="py function">
<dt class="sig sig-object py" id="pyaesthetics.selfsimilarity.hog">
<span class="sig-prename descclassname"><span class="pre">pyaesthetics.selfsimilarity.</span></span><span class="sig-name descname"><span class="pre">hog</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">orientations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">9</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pixels_per_cell</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(8,</span> <span class="pre">8)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cells_per_block</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(3,</span> <span class="pre">3)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">block_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'L2-Hys'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visualize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_sqrt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_vector</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyaesthetics.selfsimilarity.hog" title="Link to this definition">¶</a></dt>
<dd><p>Extract Histogram of Oriented Gradients (HOG) for a given image.</p>
<p>Compute a Histogram of Oriented Gradients (HOG) by</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>(optional) global image normalization</p></li>
<li><p>computing the gradient image in <cite>row</cite> and <cite>col</cite></p></li>
<li><p>computing gradient histograms</p></li>
<li><p>normalizing across blocks</p></li>
<li><p>flattening into a feature vector</p></li>
</ol>
</div></blockquote>
<section id="parameters">
<h2>Parameters<a class="headerlink" href="#parameters" title="Link to this heading">¶</a></h2>
<dl>
<dt>image<span class="classifier">(M, N[, C]) ndarray</span></dt><dd><p>Input image.</p>
</dd>
<dt>orientations<span class="classifier">int, optional</span></dt><dd><p>Number of orientation bins.</p>
</dd>
<dt>pixels_per_cell<span class="classifier">2-tuple (int, int), optional</span></dt><dd><p>Size (in pixels) of a cell.</p>
</dd>
<dt>cells_per_block<span class="classifier">2-tuple (int, int), optional</span></dt><dd><p>Number of cells in each block.</p>
</dd>
<dt>block_norm<span class="classifier">str {‘L1’, ‘L1-sqrt’, ‘L2’, ‘L2-Hys’}, optional</span></dt><dd><p>Block normalization method:</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">L1</span></code></dt><dd><p>Normalization using L1-norm.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">L1-sqrt</span></code></dt><dd><p>Normalization using L1-norm, followed by square root.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">L2</span></code></dt><dd><p>Normalization using L2-norm.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">L2-Hys</span></code></dt><dd><p>Normalization using L2-norm, followed by limiting the
maximum values to 0.2 (<cite>Hys</cite> stands for <cite>hysteresis</cite>) and
renormalization using L2-norm. (default)
For details, see <a class="footnote-reference brackets" href="#id7" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a>, <a class="footnote-reference brackets" href="#id10" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a>.</p>
</dd>
</dl>
</dd>
<dt>visualize<span class="classifier">bool, optional</span></dt><dd><p>Also return an image of the HOG.  For each cell and orientation bin,
the image contains a line segment that is centered at the cell center,
is perpendicular to the midpoint of the range of angles spanned by the
orientation bin, and has intensity proportional to the corresponding
histogram value.</p>
</dd>
<dt>transform_sqrt<span class="classifier">bool, optional</span></dt><dd><p>Apply power law compression to normalize the image before
processing. DO NOT use this if the image contains negative
values. Also see <cite>notes</cite> section below.</p>
</dd>
<dt>feature_vector<span class="classifier">bool, optional</span></dt><dd><p>Return the data as a feature vector by calling .ravel() on the result
just before returning.</p>
</dd>
<dt>channel_axis<span class="classifier">int or None, optional</span></dt><dd><p>If None, the image is assumed to be a grayscale (single channel) image.
Otherwise, this parameter indicates which axis of the array corresponds
to channels.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 0.19: </span><cite>channel_axis</cite> was added in 0.19.</p>
</div>
</dd>
</dl>
</section>
<section id="returns">
<h2>Returns<a class="headerlink" href="#returns" title="Link to this heading">¶</a></h2>
<dl class="simple">
<dt>out<span class="classifier">(n_blocks_row, n_blocks_col, n_cells_row, n_cells_col, n_orient) ndarray</span></dt><dd><p>HOG descriptor for the image. If <cite>feature_vector</cite> is True, a 1D
(flattened) array is returned.</p>
</dd>
<dt>hog_image<span class="classifier">(M, N) ndarray, optional</span></dt><dd><p>A visualisation of the HOG image. Only provided if <cite>visualize</cite> is True.</p>
</dd>
</dl>
</section>
<section id="raises">
<h2>Raises<a class="headerlink" href="#raises" title="Link to this heading">¶</a></h2>
<dl class="simple">
<dt>ValueError</dt><dd><p>If the image is too small given the values of pixels_per_cell and
cells_per_block.</p>
</dd>
</dl>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading">¶</a></h2>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id3" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients">https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients</a></p>
</aside>
<aside class="footnote brackets" id="id4" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id11">2</a><span class="fn-bracket">]</span></span>
<p>Dalal, N and Triggs, B, Histograms of Oriented Gradients for
Human Detection, IEEE Computer Society Conference on Computer
Vision and Pattern Recognition 2005 San Diego, CA, USA,
<a class="reference external" href="https://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf">https://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf</a>,
<a href="#id5"><span class="problematic" id="id6">:DOI:`10.1109/CVPR.2005.177`</span></a></p>
</aside>
<aside class="footnote brackets" id="id7" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">3</a><span class="fn-bracket">]</span></span>
<p>Lowe, D.G., Distinctive image features from scale-invatiant
keypoints, International Journal of Computer Vision (2004) 60: 91,
<a class="reference external" href="http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf">http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf</a>,
<a href="#id8"><span class="problematic" id="id9">:DOI:`10.1023/B:VISI.0000029664.99615.94`</span></a></p>
</aside>
<aside class="footnote brackets" id="id10" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">4</a><span class="fn-bracket">]</span></span>
<p>Dalal, N, Finding People in Images and Videos,
Human-Computer Interaction [cs.HC], Institut National Polytechnique
de Grenoble - INPG, 2006,
<a class="reference external" href="https://tel.archives-ouvertes.fr/tel-00390303/file/NavneetDalalThesis.pdf">https://tel.archives-ouvertes.fr/tel-00390303/file/NavneetDalalThesis.pdf</a></p>
</aside>
</aside>
</section>
<section id="notes">
<h2>Notes<a class="headerlink" href="#notes" title="Link to this heading">¶</a></h2>
<p>The presented code implements the HOG extraction method from <a class="footnote-reference brackets" href="#id4" id="id11" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a> with
the following changes: (I) blocks of (3, 3) cells are used ((2, 2) in the
paper); (II) no smoothing within cells (Gaussian spatial window with sigma=8pix
in the paper); (III) L1 block normalization is used (L2-Hys in the paper).</p>
<p>Power law compression, also known as Gamma correction, is used to reduce
the effects of shadowing and illumination variations. The compression makes
the dark regions lighter. When the kwarg <cite>transform_sqrt</cite> is set to
<code class="docutils literal notranslate"><span class="pre">True</span></code>, the function computes the square root of each color channel
and then applies the hog algorithm to the image.</p>
</section>
</dd></dl>

</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">pyaesthetics</a></h1>









<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api.html">API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../features.html">Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gettingstarted.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Examples</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2024, Giulio Gabrieli.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.0.2</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
      |
      <a href="../_sources/_autosummary/pyaesthetics.selfsimilarity.hog.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>